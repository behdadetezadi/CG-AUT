{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2f6358e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "642d7555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 105s 9us/step\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing\n",
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2fd5f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape images to the required dimensions for the network\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ccf1b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize images\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Convert labels to one-hot encoding format\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8184d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Architecture\n",
    "\n",
    "# Create a Sequential object for defining the network architecture\n",
    "model = Sequential()\n",
    "# Add a Convolutional layer to the network with 32 filters of size 3x3 and ReLU activation function\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "# Add a MaxPooling layer with pool size 2x2\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "# Flatten the data to a 1D vector\n",
    "model.add(Flatten())\n",
    "# Add a Dense layer with 10 neurons and softmax activation function for multi-class classification\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc0b4af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "422/422 [==============================] - 6s 13ms/step - loss: 0.3839 - accuracy: 0.8970 - val_loss: 0.1532 - val_accuracy: 0.9612\n",
      "Epoch 2/5\n",
      "422/422 [==============================] - 6s 13ms/step - loss: 0.1494 - accuracy: 0.9578 - val_loss: 0.0958 - val_accuracy: 0.9740\n",
      "Epoch 3/5\n",
      "422/422 [==============================] - 6s 14ms/step - loss: 0.0985 - accuracy: 0.9733 - val_loss: 0.0728 - val_accuracy: 0.9818\n",
      "Epoch 4/5\n",
      "422/422 [==============================] - 6s 14ms/step - loss: 0.0780 - accuracy: 0.9783 - val_loss: 0.0654 - val_accuracy: 0.9827\n",
      "Epoch 5/5\n",
      "422/422 [==============================] - 6s 14ms/step - loss: 0.0664 - accuracy: 0.9810 - val_loss: 0.0624 - val_accuracy: 0.9838\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4644958e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Train the network on the training data for 5 epochs with a batch size of 128 and 10% validation split\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=5, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "731f21ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 7s 24ms/step - loss: 0.0662 - accuracy: 0.9789\n",
      "Test Loss: 0.06621025502681732\n",
      "Test Accuracy: 0.9789000153541565\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "\n",
    "# Evaluate the network on the test data\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "# Print the test loss and accuracy\n",
    "print('Test Loss:', loss)\n",
    "print('Test Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6196666",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    " برای آموزش شبکه، در اولین دوره  دقت آموزش 89.70% و دقت اعتبارسنجی 96.12% بوده است. سپس با ادامه آموزش، دقت آموزش و اعتبارسنجی افزایش یافته و در دوره‌های بعدی به دقت بالاتری رسیده است. در آخرین دوره آموزش، دقت آموزش 98.10% و دقت اعتبارسنجی 98.38% بوده است\n",
    "    .\n",
    "برای ارزیابی شبکه روی داده‌های تست، دقت 97.89% و خطا (loss) 0.0662 گزارش شده است.\n",
    "با توجه به نتایج، شبکه CNN  به خوبی عمل می‌کند و دقت قابل قبولی در تشخیص ارقام دست‌نویس را دارد.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49717b8",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "نتایج شبکه به طور کلی بسیار خوب بوده است. دقت بالای 97٪ در مجموعه تست به معنای این است که شبکه با موفقیت قادر به تشخیص اعداد دست‌نویس در دیتاست MNIST است. همچنین، خطا (loss) کمی نیز گزارش شده است، که نشان می‌دهد شبکه در فرایند یادگیری به خوبی پیشرفت کرده است.\n",
    "با این حال، همیشه می‌توان بهبودی در عملکرد شبکه ایجاد کرد. برخی از راهکارهای ممکن برای بهبود عملکرد شبکه عبارتند از:\n",
    "افزایش عمق شبکه: با افزودن لایه‌های پیچشی و لایه‌های Fully Connected به شبکه، می‌توانید پیچیدگی مدل را افزایش داده و عملکرد آن را بهبود بخشید.\n",
    " تغییر هایپرپارامترها: هاپرپارامترهای مانند نرخ یادگیری، اندازه دسته (batch size) و تعداد دوره‌های آموزش (epochs) می‌توانند تأثیر زیادی بر عملکرد شبکه داشته باشند. با آزمایش و تنظیم این پارامترها می‌توانید به نتایج بهتری برسید.\n",
    "استفاده از تکنیک‌های منظم‌سازی (regularization): تکنیک‌هایی مانند Dropout و L2 regularization می‌توانند برای کاهش بیش‌برازش (overfitting) مدل و افزایش قدرت تعمیم‌پذیری آن مفید باشند.\n",
    "آزمون شبکه با دیتاهای جدید: اگر امکان دارد، می‌توانید شبکه خود را با دیتاهای جدید یا تعداد بیشتری از داده‌های تست ارزیابی کنید تا مطمئن شوید که عملکرد آن بهبود یافته است.\n",
    "پیاده‌سازی این تغییرات و آزمایش‌های مختلف می‌تواند کمک کند تا بهبودی در عملکرد شبکه دست‌یافت.\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
